# 프로젝트명 : 우리아이 지킴이
* ### 목표 : 코로나 블루 대처를 위한 스마트 로봇 및 어플 개발  
최근에 전국 269만 초중고학생들이 학교에서 수업을 받고 있지만 10명 중 1명은 불안해서 또는 의심 증상이 있다는 이유로 학교에 가지 않고 있으며, 학교 전체가 등교를 미룬 곳도 800곳을 넘어서고 있다.  

이에 학부모의 불안이 고조되고 있는 현 상황에서 학부모들이 가정 및 직장에서 아이의 건강상태 및 심리상태를 비대면으로 모니터링을 하고, 아이들에게 친숙한 펭수로봇을 통해 질병관리본부에서 제작한 감염병예방수칙을 홍보하면서 아이들의 표정변화 등을 빅데이터 및 AI 기술을 적용한 시제품을 개발하기로했다.


<div>
<img src="https://user-images.githubusercontent.com/59993079/83984279-4e661b80-a96f-11ea-9b0f-1ec829fe85cb.jpg">
<img src="https://user-images.githubusercontent.com/59993079/83984286-558d2980-a96f-11ea-90f5-9332dd8d5cb5.jpg">
<img src="https://user-images.githubusercontent.com/59993079/83984291-5d4cce00-a96f-11ea-9ae8-1205f62aa0a3.jpg">
<img src="https://user-images.githubusercontent.com/59993079/83984292-6178eb80-a96f-11ea-8a10-7caabd9abf7e.jpg">
</div

------------------
# 프로젝트 담당업무
* Cross-Platform인 Kivy를 활용한 UI/UX 설계 및 구현
* 로봇에서 전송되는 정보를 활용한 빅데이터 시각화 설계 및 구현
* 아이들의 그림정보를 획득하여 AI분석을 위한 피쳐분석 설계 및 구현
* 관리자, 어린이, 부모용 로그인정보 DB설계 및 구현
* PySpark Linux 서버 시스템 Build
* PySpark를 활용한 정규표현식 기반의 정제 코드 빌드

# Kivy App

* ## 키비란
  1. 파이썬의 오픈소스 라이브러리로써 Multi-touch같은 유저인터페이스에 맞춰 설계된 어플리케이션 개발 툴입니다  
  2. Flexible - 키비는 Android기반 스마트 폰 및 태블릿을 포함한 다양한 장치에서 실행될 수 있고 지원하는 모든 주요 운영 체제 (윈도우, 리눅스, OS X)에 빠르게 적응할 수 있습니다  
  3. Concentration - 키비는 몇 줄의 코드로 간단한 응용 프로그램을 작성할 수 있습니다.   
  Kivy 프로그램은 파이썬 프로그래밍 언어를 사용하여 만들어 졌는데 , 정교한 사용자 인터페이스를 만들기 위해 자체 설명 언어 인 Kivy Language 를 제공합니다.    
  이 언어를 사용하면 응용 프로그램 요소를 빠르게 설정, 연결 및 정렬 할 수 있습니다.  컴파일러 설정을 사용하는 것보다 응용 프로그램의 본질에 집중하게 해줍니다    
  
* ## Kivy의 레이아웃
  1. Kivy에는 자주쓰는 BoxLayout, GridLayout, FloatLayout등을 포함해 8개정도의 레이아웃을 가지고 있는데 각각 조금씩의 차이는 있지만 결국은 버튼이나 라벨등을 넣기위한 공간이라고 생각하면 됩니다.  
  그리고 이 레이아웃들은 공간을 특정한 크기가 아니라 비율로 나타내게 되는데 이것으로 인해 위에서 언급한 Kivy의 Flexible한 특성을 살려 여러Android기계에 쉽게 호환됩니다  

  2. __**앱을 개발할 때 GridLayout을 가장 많이 사용했고 칼럼값을 주지 않으면 구석에 박히는 특성때문에 처음에 에러를 잡기 어려웠으나 BoxLayout과 같이 쓰게되면서 칼럼값을 까먹지 않게 되었고 레이아웃의 블록처럼 위젯을 쌓을 수 있는 기능을 이용했습니다.  
  완성된 앱의 GUI가 디바이스 화면 크기나 비율에 종속되지 않고 제가 만들고 생각했던 비율과 GUI가 구현 되었습니다**__
  
  3. **키비 위젯은 레이아웃 안에서 위치나 위젯 크기를 소수점 비율로 지정할 수 있습니다**
  <div><img src="https://user-images.githubusercontent.com/59993079/83984691-5626bf80-a971-11ea-8742-589022ae09ba.png"></div>  
  **레이아웃안의 Image위젯은 전체 크기의 0.5 즉 50%를 차지하게 됩니다**

* ## 키비의 .kv 확장자 언어와 python 실행파일과의 교류
  1. 키비는 마치 HTML과 CSS처럼 논리적인 부분과 UI배치하는 부분을 python파일과 kv파일로 분리하여 작업하여 각각의 분야에 집중하여 개발할 수 있습니다

  2. 위에서 말한대로 Kivy의 버튼이 위치하는곳은 UI영역이고 버튼의 동작 함수들의 구현은 python 파일 내에서 이루어집니다 그렇다면 함수들이 구현되는 python 스크립트 내에서 GUI를 구성하는 kv확장자 내에 영향을 줄 수 있어야 했고 세가지정도 방법이 있는데 저는 위젯마다 id를 배당해서 python파일 내에서 kv파일 내의 id에 접근하고 원하는 위젯들을 통제 했습니다
  3. **코드 길이가 길어지면서 파일을 소분해야 했는데 파일이 모듈별로 각각 떨어져 있고 함수 적용을 할때 보통 root경로를 이용하여 python파일에서 작업하게 되는데 모듈이 떨어져 있으니 root경로가 원하는 경로로 설정되지 않았습니다.**   
     **그때 내부적으로 id에 접근하기가 어려워졌습니다. 그래서 추가로 다른 방법이 필요해졌고 kivy에서 제공하는 위젯사이의 parent, children 속성을 이용해 모듈로 떨어져 있어도 원하는 위젯에 접근이 가능해졌습니다**

# Docker & pyspark & hadoop
* ## Docker
   1. 도커는 컨테이너 기반의 오픈소스 가상화 플랫폼입니다.
  다양한 프로그램, 실행환경을 컨테이너로 추상화하고 동일한 인터페이스를 제공하여 프로그램의 배포 및 관리를 단순하게 해줍니다.  
  백엔드 프로그램, 데이터베이스 서버, 메시지 큐등 어떤 프로그램도 컨테이너로 추상화할 수 있고 조립PC, AWS, Azure, Google cloud등 어디에서든 실행할 수 있습니다.  
   2. **도커를 이용해서 pyspark와 jupyter notebook을 연동해놓은 이미지를 pull 해서 -p 포트 명령어로 내 현재 OS를 도커 내부 컨테이너의 jupyter-notebook으로 연결하여 간단한 서버를 구축할수 있었습니다. 특히 -p 포트 포워딩부분이 개념정리가 힘들었습니다. 이외에도 기본 명령어, -v 마운팅 --name 네이밍등 기본 명령어들을 익힐수 있었고 추후에 자기 프로젝트를 도커 이미지로 만들어 클라우드 서비스를 이용하여 호스팅 할 계획입니다**
 
* ## pyspark & hadoop
  1. 하둡은 대용량 데이터를 처리하는 새로운 패러다임이며
  그 핵심은 hdfs와 mapreduce이다
  2. hdfs란 Hadoop Distributed File System 의 약자로 여러 서버를 클러스터로 묶어 처리할 데이터를 분산 저장한다 또한 fault tolerance로써 데이터를 일정 단위로 쪼개어 클러스터에 첫번째 스토리지에 저장하고 첫 번째 스토리지는 동일한 데이터를 옆 서버의 스토리지에 저장하게 되어 특정 서버가 다운이 된다고 하더라도 데이터를 처리하는데 문제가 없게 합니다

  3. mapreduce란 분산저장과 비슷하게 데이터처리도 분산으로 하는 개념을 말합니다. map과 reduce과정으로 나뉘어져 있으며 map은 데이터들을 key,value로 모으고 key를 기준으로 정렬하여 reduce에 넘기게 됩니다 그러면 reduce에서는 key기준으로 단 하나의 value가 남을 때까지 reduce를 계속하여 작업합니다    
    **key를 아동 이름으로하고 value값을 체온이라고 놔뒀을때 key값을 기준으로 정렬한뒤에 reduce에서 value값이 하나가 남을때까지 평균치를 구해주면 마지막에 key,value값이 아동이름과 체온값1개로 reduce되어집니다**
  
  4. spark는 하둡과 같이 사용할수 있는데 하둡과 다르게 메모리 기반으로 데이터를 처리하여 하둡보다 훨씬 나은 성능을 기대할 수 있습니다 
  
 
  5. 
      spark에서도 dataframe형태를 제공합니다 pandas의 dataframe과 형식이나 문법이 비슷해서 적응하기가 상대적으로 쉬웠습니다.       
     평균 데이터를 구할일이 많아서 groupby함수와 mean()으로 groupby인자로 '시간데이터'를 주고 mean()함수로 평균온도를 구하여 시각화를 하려고 했습니다. 또한 sql문을 섞어 쓸 수 있어서 기본적인 CRUD 개념이 어렵지 않게 다가 왔습니다.    
     **sql문에서도 똑같이 groupby와 avg()함수로 원하는 데이터를 뽑을수 있었습니다 이번 프로젝트에서 하둡 클러스터링, master-node, worker-node등을 구축하지 못했는데 클라우드 시스템으로 하둡 시스템을 구축할 계획입니다**


# Reguler Expression

* 정규표현식의 사전적인 의미로는 특정한 규칙을 가진 문자열의 집합을 표현하는데 사용하는 형식 언어입니다.   
주로 Programming Language나 Text Editor 등 에서 문자열의 검색과 치환을 위한 용도로 쓰이고 있습니다.   
입력한 문자열에서 특정한 조건을 표현할 경우 일반적인 조건문으로는 다소 복잡할 수도 있지만, 정규표현식을 이용하면 매우 간단하게 표현 할 수 있습니다. 하지만 코드가 간단한 만큼 가독성이 떨어져서 표현식을 숙지하지 않으면 이해하기 힘들다는 문제점이 있습니다.

* #### 데이터에 적용하기
  * **정규식으로 아이들 체온데이터 찾아내기**  
  체온을 나타내는 데이터 형식이 36.8 이라고 하면 여기서 찾아낼 수 있는 정규표현식 패턴은 '\d{2}\.\d'로 데이터 내에서 모든 체온데이터를 찾을수 있습니다.
    \d는 digit으로써 0~9까지 숫자를 의미하고 {}안의 숫자는 바로앞 패턴이 몇번 반복되는가를 나타냅니다 그리고 소수점 '.'앞에 \가 붙은 이유는 소수점 자체가 정규표현식에서 특별한 의미(무슨 문자던지 다받는 joker같은 성질)를 가지고 있기 때문에 \.을 해주면 소수점 그대로를 찾아냅니다
  
  
  
  * **정규식으로 아이들 주민등록번호 찾아내기**  

      주민등록번호구성은 대부분 다음과 같습니다  
      
      123456 - 1234567  
      
      
      앞의 여섯자리는 차례대로 출생년도, 월, 일입니다 그리고 뒷자리 첫 번째 숫자는 성별을 나타냅니다.  
      월을 1~12월로 제한하고 일날짜를 1~31로 제한한다음 남자성별인 1만 찾아보도록 하겠습니다

      ‘^\d{2}(0[1-9]|1[0-2])(0[1-9]|[12][0-9]|[3][01])-[1][0-9]{6}$'

      맨 앞의 ‘^’는 패턴의 시작을 말하고 맨뒤의 ‘$’는 패턴의 끝을 의미합니다

      \d{2}는 출생년도를 찾기위한 패턴이고 \d라는 0~9를 의미하는 숫자가 {2}로 두 번 반복됩니다

      (0[1-9]|1[0-2])에서 0[1-9]는 01~09 월을 나타내고 바로 뒤에있는 ‘|’는 or을 나타내는 구분자입니다.  
      그리고 1[0-2]를 이용해서 출생월을 01~12로 한정 지을 수 있었습니다.  

      (0[1-9]|[12][0-9]|[3][01])에서는 위와 같은 방식으로 01~31일 이라는 특정한 날짜를 찾을수 있습니다.  

      -[1][0-9]{6} 부분은 주민등록번호 뒷자리로써 남자아이인 1을 찾기로 했으므로 1을 적었고 뒤에 나올 패턴은 아무숫자나6개가 나오면 됨으로 {6}을 써서 앞패턴을 반복하였습니다.
